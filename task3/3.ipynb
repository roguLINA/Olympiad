{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "task3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXnU144cmDNO"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT0T4P61mM_e"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "import keras\r\n",
        "from keras import backend as K\r\n",
        "print(tf.__version__)\r\n",
        "print(keras.__version__)\r\n",
        "\r\n",
        "from tensorflow.keras import optimizers\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout\r\n",
        "from keras.layers.advanced_activations import LeakyReLU\r\n",
        "from keras import regularizers\r\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXSqERp4rabv"
      },
      "source": [
        "data_test = np.load('test.npy', allow_pickle=True)\n",
        "data_train = np.load('train.npy', allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go0ULK2vrk5m"
      },
      "source": [
        "data_train = np.concatenate([data1, data2, data3, data4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbA__gnvokLi"
      },
      "source": [
        "x_train = data_train[:,0]\n",
        "y_train = data_train[:,1]\n",
        "\n",
        "x_test = data_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVe7qdxVokN6"
      },
      "source": [
        "# Interpolation \n",
        "import cv2\n",
        "\n",
        "for i in range(x_train.shape[0]):\n",
        "  x_train[i] = cv2.resize(x_train[i], (77,77), interpolation=cv2.INTER_CUBIC)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S609ldQqrTFg"
      },
      "source": [
        "x_train_new = []\n",
        "for x in x_train:\n",
        "  x_train_new.append(x)\n",
        "x_train_new = np.array(x_train_new)\n",
        "x_train_new = x_train_new.reshape((x_train_new.shape[0], x_train_new.shape[1], x_train_new.shape[2], 1))\n",
        "print(x_train_new.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gucLDhT_1Vo"
      },
      "source": [
        "x_train_new.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSxzX4ydI_d0"
      },
      "source": [
        "y_train = np.vstack([y_train, y_train])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK5Z9LMvokQm"
      },
      "source": [
        "train_gen = ImageDataGenerator(zoom_range=[0.8, 1.2], width_shift_range=0.1, height_shift_range=0.1)\n",
        "iterator = train_gen.flow(x_train_new, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZvm1zS7wY91"
      },
      "source": [
        "def reset_tf_session():\n",
        "    curr_session = tf.get_default_session()\n",
        "    if curr_session is not None:\n",
        "        curr_session.close()\n",
        "    tf.keras.backend.clear_session()\n",
        "    config = tf.ConfigProto()\n",
        "    config.gpu_options.allow_growth = True\n",
        "    s = tf.InteractiveSession(config=config)\n",
        "    tf.keras.backend.set_session(s)\n",
        "    return s\n",
        "\n",
        "s = reset_tf_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8KRSkb59QQJ"
      },
      "source": [
        "weight_decay = 1e-4\n",
        "initializer='glorot_normal'\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=32, padding='same', kernel_size=(11,11), input_shape=(77,77,1), kernel_initializer=initializer))\n",
        "model.add(LeakyReLU(0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters=32, padding='same', kernel_size=(11,11), kernel_initializer=initializer))\n",
        "model.add(LeakyReLU(0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "    \n",
        "model.add(Conv2D(filters=64, padding='same', kernel_size=(11,11), kernel_initializer=initializer))\n",
        "model.add(LeakyReLU(0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters=64, padding='same', kernel_size=(11,11), kernel_initializer=initializer))\n",
        "model.add(LeakyReLU(0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(filters=64, padding='same', kernel_size=(7,7), kernel_initializer=initializer))\n",
        "model.add(LeakyReLU(0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters=64, padding='same', kernel_size=(7,7), kernel_initializer=initializer))\n",
        "model.add(LeakyReLU(0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "    \n",
        "model.add(Conv2D(filters=128, padding='same', kernel_size=(3,3), kernel_initializer=initializer))\n",
        "model.add(LeakyReLU(0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters=128, padding='same', kernel_size=(3,3), kernel_initializer=initializer))\n",
        "model.add(LeakyReLU(0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        " \n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, kernel_initializer=initializer))\n",
        "model.add(LeakyReLU(0.1))\n",
        "model.add(Dense(1000, kernel_initializer=initializer))\n",
        "model.add(Activation(\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqIX9zbewZJF"
      },
      "source": [
        "INIT_LR = 5e-3\n",
        "\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',  \n",
        "    optimizer=keras.optimizers.adamax(lr=INIT_LR),  \n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHpl1pQVwZLo"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0He-zVI5u7w"
      },
      "source": [
        "history1 = model.fit_generator(\n",
        "    iterator,\n",
        "    steps_per_epoch=4000,\n",
        "    epochs=30,\n",
        "    shuffle=True,\n",
        "    verbose=1,\n",
        "    initial_epoch=0\n",
        ") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpqjpEqGaGfC"
      },
      "source": [
        "# Interpolation \n",
        "import cv2\n",
        "\n",
        "for i in range(x_test.shape[0]):\n",
        "  x_test[i] = cv2.resize(x_test[i], (77,77), interpolation=cv2.INTER_CUBIC)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3KKSRXhaGcc"
      },
      "source": [
        "x_test_new = []\n",
        "for x in x_test:\n",
        "  x_test_new.append(x)\n",
        "x_test_new = np.array(x_test_new)\n",
        "x_test_new = x_test_new.reshape((x_test_new.shape[0], x_test_new.shape[1], x_test_new.shape[2], 1))\n",
        "print(x_test_new.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qAduzaj6B2M"
      },
      "source": [
        "ans = model.predict_classes(x_test_new, 4000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tcthxeOF12G"
      },
      "source": [
        "my_submit = pd.DataFrame(data=ans, columns = ['Category'])\n",
        "my_submit['Id'] = range(1, x_test.shape[0] + 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gmPNEe-Gyiz"
      },
      "source": [
        "my_submit.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKvC9UfYHmYo"
      },
      "source": [
        "my_submit.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ed8CDVbHZlr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}